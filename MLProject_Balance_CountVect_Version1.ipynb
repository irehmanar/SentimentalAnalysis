{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud\n",
    "from itertools import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "import logging\n",
    "\n",
    "# !pip install -U -q PyDrive\n",
    "# !pip install -q glove_python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('universal_tagset')\n",
    "# nltk.download('wordnet')\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('E:\\Semester5\\ML\\Project\\Electronics_5.json', orient='columns',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any 'neutral' ratings equal to 3\n",
    "df = df[df['overall'] != 3]\n",
    "\n",
    "# # df = pd.concat(f1)\n",
    "# df = df.sample(frac=0.7, random_state=0) #uncomment to use full set of data\n",
    "# # Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode 4s and 5s as 1 (positive sentiment) and 1s and 2s as 0 (negative sentiment)\n",
    "df['Sentiment'] = np.where(df['overall'] > 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataset by the 'overall' column\n",
    "df = df.sort_values(by=['Sentiment'])\n",
    "\n",
    "# Select the first 20,000 rows for negative sentiment\n",
    "dfnegative = df[df['Sentiment'] == 0].head(20000)\n",
    "\n",
    "# Select the first 20,000 rows for positive sentiment\n",
    "dfpositive = df[df['Sentiment'] == 1].head(20000)\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([dfnegative, dfpositive])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Number of Reviews less than rating 3\")\n",
    "df[df['overall'] < 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Number of Reviews greater than 3\")\n",
    "df[df['overall'] > 3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Size of Dataset\",df.shape)\n",
    "print('Distribution of Positive and Negative Reviews, Three being the threshold')\n",
    "df.hist('overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['reviewText']\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(raw_text, remove_stopwords=True, stemming=False, split_text=False, \\\n",
    "             ):\n",
    "    '''\n",
    "    Convert a raw review to a cleaned review\n",
    "    '''\n",
    "    text = BeautifulSoup(raw_text, 'lxml').get_text()  #remove html\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)  # remove non-character\n",
    "    words = letters_only.lower().split() # convert to lower case \n",
    "    \n",
    "    if remove_stopwords: # remove stopword\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        stops.remove('not')\n",
    "        stops.remove('no')\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if stemming==True: # stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmer = SnowballStemmer('english') \n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "        \n",
    "    if split_text==True:  # split text\n",
    "        return (words)\n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = []\n",
    "    \n",
    "for d in X:\n",
    "    X_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def grid_search(X_train, y_train,X_test,y_test):\n",
    "    classifiers = ['Adaboost','KNN','SVM','MNB','LR'];\n",
    "    pipeline1 = Pipeline([(\n",
    "    ('clf', AdaBoostClassifier())\n",
    "    )])\n",
    "\n",
    "    pipeline2 = Pipeline([(\n",
    "    ('clf', KNeighborsClassifier())\n",
    "    )])\n",
    "\n",
    "    pipeline3 = Pipeline([(\n",
    "    ('clf', SVC())\n",
    "    )])\n",
    "\n",
    "    pipeline4 = Pipeline([(\n",
    "    ('clf', MultinomialNB())\n",
    "    )])\n",
    "    \n",
    "    pipeline5 = Pipeline([(\n",
    "    ('clf', LogisticRegression())\n",
    "    )])\n",
    "\n",
    "    parameters1 = {\n",
    "    'clf__n_estimators': [50,100,150],\n",
    "        'clf__learning_rate': [0.1,1.0],\n",
    "\n",
    "    }\n",
    "\n",
    "    parameters2 = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 10],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    }\n",
    "\n",
    "    parameters3 = {\n",
    "    'clf__C': [0.01, 0.1, 1.0],\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__gamma': [0.01, 0.1, 1.0],\n",
    "\n",
    "    }\n",
    "    parameters4 = {\n",
    "    'clf__alpha': [0.01, 0.1, 1.0],\n",
    "    }\n",
    "    \n",
    "    parameters5 = {\n",
    "        'clf__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0], \n",
    "        \"clf__penalty\":[\"l1\",\"l2\"]\n",
    "    }\n",
    "\n",
    "    pars = [parameters3]\n",
    "    pips = [pipeline3]\n",
    "\n",
    "    print (\"Starting Gridsearch..\")\n",
    "    for i in range(len(pars)):\n",
    "        gs = GridSearchCV(pips[i], pars[i], verbose=2, n_jobs=-1)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        print (\"Finished Gridsearch For\",classifiers[i])\n",
    "        print('The Best Model Achieved for {} with Score {} and the best parameters are {}'.format(classifiers[i],gs.best_score_,gs.best_params_))\n",
    "        y_pred = gs.predict(X_test)\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVect = CountVectorizer(min_df=50, ngram_range=(1,2), strip_accents='unicode', binary=True)\n",
    "X_all_countVect = countVect.fit_transform(X_cleaned)\n",
    "\n",
    "print(\"Number of features : %d \\n\" % len(countVect.get_feature_names_out()))  # 1722\n",
    "print(\"Show some feature names : \\n\", countVect.get_feature_names_out()[::1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target): \n",
    "    classifier=KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train_countVect,y_train)\n",
    "\n",
    "    y_pred=classifier.predict(X_test_countVect)\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train_countVect)\n",
    "    # print('KNN Results:')\n",
    "    # print(\"KNN Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "    # print(\"KNN Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "    # print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    return metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "def svc_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names): \n",
    "  from sklearn import svm\n",
    "  clf=svm.SVC(kernel='linear')\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "\n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "# scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "# print(\"scores\",scores.avg)\n",
    "  # print('SVM Results:')\n",
    "  # print(\"SVM Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  # print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  # print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  # print(\"SVM Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  # print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "  return metrics.accuracy_score(y_test,y_pred)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier\n",
    "def nb_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names): \n",
    "\n",
    "  clf = MultinomialNB()\n",
    "  clf.fit(X_train_countVect.toarray(),y_train)\n",
    "\n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "\n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "#   print('NB Results:')\n",
    "# #   y_pred_train =clf.predict(countVect.transform(X_test_cleaned))\n",
    "#   print(\"MNB Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "#   print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "#   print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "#   print(\"MNB Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "#   print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "\n",
    "  return metrics.accuracy_score(y_test,y_pred)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def lr_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names): \n",
    "  lr = LogisticRegression()\n",
    "  lr.fit(X_train_countVect.toarray(), y_train)\n",
    "\n",
    "\n",
    "  y_pred=lr.predict(X_test_countVect)\n",
    "\n",
    "  y_pred_train =lr.predict(X_train_countVect)\n",
    "  # print('LR Results:')\n",
    "  # #   y_pred_train =clf.predict(countVect.transform(X_test_cleaned))\n",
    "  # print(\"LR Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  # print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  # print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  # print(\"LR Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  # print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #   Decision Trees\n",
    "def dt_classifier(X_train_countVect,y_train,X_test_countVect,y_test,target_names): \n",
    "  clf = AdaBoostClassifier(n_estimators=400,learning_rate=1)\n",
    "  clf.fit(X_train_countVect,y_train)\n",
    "  \n",
    "  y_pred=clf.predict(X_test_countVect)\n",
    "  \n",
    "  y_pred_train =clf.predict(X_train_countVect)\n",
    "\n",
    "\n",
    "  # print('Adaboosting Results:')\n",
    "  # print(\"Adaboosting DT Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "  # print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "  # print(\"Confusion Matrix\",confusion_matrix(y_test, y_pred))    \n",
    "  # print(\"Adaboosting DT Train Accuracy:\",metrics.accuracy_score(y_train,y_pred_train))\n",
    "  # print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "  \n",
    "  return metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = []\n",
    "svm = []\n",
    "dt = []\n",
    "nb = []\n",
    "lr = []\n",
    "rus = RandomUnderSampler(random_state=777)\n",
    "X_RUS, y_RUS = rus.fit_resample(X_all_countVect, y)  # Updated method\n",
    "target_names = ['Positive', 'Negative']\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in skf.split(X_RUS, y_RUS):\n",
    "    X_train_countVect = X_RUS[train_index]\n",
    "    y_train = y_RUS[train_index]\n",
    "    X_test_countVect = X_RUS[test_index]\n",
    "    y_test = y_RUS[test_index]\n",
    "    \n",
    "    knn_mean = knn_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\n",
    "    knn.append(knn_mean)\n",
    "    dt_mean = dt_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\n",
    "    dt.append(dt_mean)\n",
    "    nb_mean = nb_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\n",
    "    nb.append(nb_mean)\n",
    "    lr_mean = lr_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\n",
    "    lr.append(lr_mean)\n",
    "    svm_mean = svc_classifier(X_train_countVect, y_train, X_test_countVect, y_test, target_names)\n",
    "    svm.append(svm_mean)\n",
    "\n",
    "    print('The Accuracy for KNN:', sum(knn) / len(knn))\n",
    "    print('The Accuracy for SVM:', sum(svm) / len(svm))\n",
    "    print('The Accuracy for DT:', sum(dt) / len(dt))\n",
    "    print('The Accuracy for MNB:', sum(nb) / len(nb))\n",
    "    print('The Accuracy for LR:', sum(lr) / len(lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
